version: '3.8'

services:
  # ML Prediction Service
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: climalaria-ml
    ports:
      - "8000:8000"
    environment:
      - FLASK_ENV=production
      - PYTHONUNBUFFERED=1
    volumes:
      - ./ml-service:/app
      - ml-models:/app/models
    networks:
      - climalaria-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Rasa Actions Server (must start before rasa-server)
  rasa-actions:
    build:
      context: ./rasa-service
      dockerfile: Dockerfile.actions
    container_name: climalaria-actions
    ports:
      - "5055:5055"
    volumes:
      - ./rasa-service/actions:/app/actions
    environment:
      - ML_SERVICE_URL=http://ml-service:8000
    networks:
      - climalaria-network
    depends_on:
      - ml-service
    restart: unless-stopped

  # Rasa NLU Server
  rasa-server:
    build:
      context: ./rasa-service
      dockerfile: Dockerfile
    container_name: climalaria-rasa
    ports:
      - "5005:5005"
    volumes:
      - ./rasa-service:/app
    environment:
      - RASA_NLU_LOG_LEVEL=INFO
    networks:
      - climalaria-network
    depends_on:
      - rasa-actions
    restart: unless-stopped
    command: >
      run
      --enable-api
      --cors "*"
      --debug

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: climalaria-frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_RASA_URL=http://localhost:5005
      - VITE_ML_SERVICE_URL=http://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    networks:
      - climalaria-network
    depends_on:
      - rasa-server
      - ml-service
    restart: unless-stopped

networks:
  climalaria-network:
    driver: bridge

volumes:
  ml-models:

